{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Symmetric Correspondence LDA#####\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot  as plt\n",
    "import numpy.matlib\n",
    "import gensim\n",
    "import itertools\n",
    "from numpy.random import *\n",
    "from scipy import optimize\n",
    "from scipy import sparse\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##多項分布の乱数を生成する関数\n",
    "def rmnom(pr, n, k, no):\n",
    "    z_id = np.argmax((np.cumsum(pr, axis=1) > np.random.rand(n).reshape(n, 1)), axis=1)\n",
    "    Z = sparse.coo_matrix((np.repeat(1, n), (no, np.array(z_id))), shape=(n, k))   #スパース行列の設定\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "####データの発生####\n",
    "##データの設定\n",
    "L = 3   #データ数\n",
    "k = 15   #トピック数\n",
    "d = 3000   #文書数\n",
    "v1 = 1000; v2 = 800; v3 = 700   \n",
    "v = [v1, v2, v3]   #語彙数\n",
    "w1 = np.random.poisson(np.random.gamma(85, 1/0.6, d), d)\n",
    "w2 = np.random.poisson(np.random.gamma(80, 1/0.65, d), d)\n",
    "w3 = np.random.poisson(np.random.gamma(75, 1/0.65, d), d)\n",
    "w = [w1, w2, w3]   #単語数\n",
    "f1 = np.sum(w1); f2 = np.sum(w2); f3 = np.sum(w3)   #総単語数\n",
    "f = np.array([f1, f2, f3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "##IDとインデックスの設定\n",
    "#IDの設定\n",
    "d_id1 = np.repeat(range(d), w1)\n",
    "d_id2 = np.repeat(range(d), w2)\n",
    "d_id3 = np.repeat(range(d), w3)\n",
    "\n",
    "#インデックスの設定\n",
    "d_list1 = [i for i in range(d)]\n",
    "d_list2 = [i for i in range(d)]\n",
    "d_list3 = [i for i in range(d)]\n",
    "for i in range(d):\n",
    "    d_list1[i] = np.array(np.where(d_id1==i)[0], dtype=\"int\")\n",
    "    d_list2[i] = np.array(np.where(d_id2==i)[0], dtype=\"int\")\n",
    "    d_list3[i] = np.array(np.where(d_id3==i)[0], dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "[2 2 2]\n"
     ]
    }
   ],
   "source": [
    "##データの生成\n",
    "rp = 0\n",
    "while True:\n",
    "    rp = rp + 1\n",
    "    print(rp)\n",
    "\n",
    "    ##パラメータの生成\n",
    "    #ディリクレ分布のパラメータ\n",
    "    alpha1 = np.repeat(0.4, L)\n",
    "    alpha2 = np.repeat(0.15, k)\n",
    "    beta1 = np.repeat(0.05, v1)\n",
    "    beta2 = np.repeat(0.05, v2)\n",
    "    beta3 = np.repeat(0.05, v3)\n",
    "\n",
    "    #ディリクレ分布からトピック分布を生成\n",
    "    theta1 = np.random.dirichlet(alpha1, d)\n",
    "    theta2 = np.zeros((d, k, L))\n",
    "    for j in range(L):\n",
    "        theta2[:, :, j] = np.random.dirichlet(alpha2, d)\n",
    "    thetat1 = theta1.copy(); thetat2 = theta2.copy()\n",
    "\n",
    "    #ディリクレ分布から単語分布を生成\n",
    "    phi1 = np.random.dirichlet(beta1, k)  \n",
    "    phi2 = np.random.dirichlet(beta2, k)  \n",
    "    phi3 = np.random.dirichlet(beta3, k)  \n",
    "\n",
    "    #出現確率が低い単語を入れ替える\n",
    "    index_v1 = np.array(range(v1))[np.max(phi1, axis=0) <= (k*5)/f1]\n",
    "    for j in range(index_v1.shape[0]):\n",
    "        phi1[np.argmax(np.random.multinomial(1, np.repeat(1/k, k), 1)), index_v1[j]] = (k*5)/f1\n",
    "    phi1 = phi1 / np.sum(phi1, axis=1).reshape(k, 1)\n",
    "    phit1 = phi1.copy()\n",
    "\n",
    "    index_v2 = np.array(range(v2))[np.max(phi2, axis=0) <= (k*5)/f2]\n",
    "    for j in range(index_v2.shape[0]):\n",
    "        phi2[np.argmax(np.random.multinomial(1, np.repeat(1/k, k), 1)), index_v2[j]] = (k*5)/f1\n",
    "    phi2 = phi2 / np.sum(phi2, axis=1).reshape(k, 1)\n",
    "    phit2 = phi2.copy()\n",
    "\n",
    "    index_v3 = np.array(range(v3))[np.max(phi3, axis=0) <= (k*5)/f3]\n",
    "    for j in range(index_v3.shape[0]):\n",
    "        phi3[np.argmax(np.random.multinomial(1, np.repeat(1/k, k), 1)), index_v3[j]] = (k*5)/f3\n",
    "    phi3 = phi3 / np.sum(phi3, axis=1).reshape(k, 1)\n",
    "    phit3 = phi3.copy()\n",
    "\n",
    "    #単語分布をリストに格納\n",
    "    phi = [phi1, phi2, phi3]\n",
    "    phit = phi.copy()\n",
    "\n",
    "    \n",
    "    ##トピックと単語を生成\n",
    "    #モードごとのオブジェクトの格納用リスト\n",
    "    Z1_list = [j for j in range(L)]\n",
    "    Z2_list = [j for j in range(L)]\n",
    "    WX_list = [j for j in range(L)]\n",
    "    word_list = [j for j in range(L)]\n",
    "\n",
    "    for m in range(L):\n",
    "        #文書ごとのオブジェクトの格納用リスト\n",
    "        WX = np.zeros((d, v[m]), dtype=\"int32\")\n",
    "        word_data = [i for i in range(d)]\n",
    "        Z1 = [i for i in range(d)]\n",
    "        Z2 = [i for i in range(d)]\n",
    "\n",
    "        for i in range(d):\n",
    "            #モード変数を生成\n",
    "            n = w[m][i]\n",
    "            z1 = np.random.multinomial(1, theta1[i, ], n)\n",
    "            z1_vec = np.dot(z1, np.arange(L))\n",
    "\n",
    "            #トピックを生成\n",
    "            z2 = np.array(rmnom(theta2[i, :, z1_vec], n, k, np.arange(n)).todense())\n",
    "            z2_vec = np.dot(z2, np.arange(k))\n",
    "\n",
    "            #単語の生成\n",
    "            words = np.array(rmnom(phi[m][z2_vec, ], n, v[m], np.arange(n)).todense())\n",
    "            word_vec = np.dot(words, np.arange(v[m]))\n",
    "\n",
    "            #文書ごとにデータを格納\n",
    "            Z1[i] = z1\n",
    "            Z2[i] = z2\n",
    "            WX[i, ] = np.sum(words, axis=0)\n",
    "            word_data[i] = words\n",
    "\n",
    "        #オブジェクトごとにデータを格納\n",
    "        WX_list[m] = WX\n",
    "        word_list[m] = np.array(list(itertools.chain(*[word_data[i] for i in range(d)])))\n",
    "        Z1_list[m] = np.array(list(itertools.chain(*[Z1[i] for i in range(d)])))\n",
    "        Z2_list[m] = np.array(list(itertools.chain(*[Z2[i] for i in range(d)])))\n",
    "    \n",
    "    #単語がすべて出現していたらbreak\n",
    "    min_word = np.zeros((L), dtype=\"int32\")\n",
    "    for j in range(L):\n",
    "        min_word[j] = np.min(np.sum(WX_list[j], axis=0))\n",
    "\n",
    "    if np.min(min_word) > 0:\n",
    "        print(min_word)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#リストを変換\n",
    "Z11 = Z1_list[0]; Z12 = Z1_list[1]; Z13 = Z1_list[2]\n",
    "Z21 = Z2_list[0]; Z22 = Z2_list[1]; Z23 = Z2_list[2]\n",
    "wd1 = np.dot(word_list[0], np.arange(v1))\n",
    "wd2 = np.dot(word_list[1], np.arange(v2))\n",
    "wd3 = np.dot(word_list[2], np.arange(v3))\n",
    "word_data1 = sparse.csr_matrix(word_list[0])\n",
    "word_data2 = sparse.csr_matrix(word_list[1])\n",
    "word_data3 = sparse.csr_matrix(word_list[2])\n",
    "del Z1_list; del Z2_list; del word_list; del WX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
